The architecture of our proposed binary classification model for Deepfake  detection is shown . Firstly, we load the dataset and split it into training and testing and validation set in the 70:15:15 ratio. We perform image pre-processing and pre-compute on the input videos to create frame folder  images for each video before training. To do so, we performed deepface detection and cropped the faces and generated new images with uniform  intervals to cover all aspects  in equal numbers and applied image augmentation on them with horizontal and vertical flips. We rescale all the images to reconcile with the input dimensions of the pre-trained architecture used in this experimentation. Furthermore, we feed the processed images into the pre-trained architecture called MT-CNN  for detecting and cropping faces in the videos and saving them in the form of images to perform feature extraction and fine tuning to feed our compromised model. The output is then classified into real and fake videos.
